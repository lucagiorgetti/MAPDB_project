{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b22621d",
   "metadata": {},
   "source": [
    " <hr style=\"border:3px solid green \"> </hr>\n",
    "\n",
    "# MAPD (mod.B) Final Project \"Analysis of Covid-19 papers\"\n",
    "\n",
    "## students \n",
    "* Luca\n",
    "* Roya Joulaei Vijouyeh\n",
    "* Mojtaba Roshana\n",
    "* Emerson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae9d5a",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This distributed computing project will be focused on the analysis of 1000 papers about\n",
    "COVID-19, SARS-CoV-2, and related coronaviruses. The dataset is a sub-sample of 1000\n",
    "items taken from the original dataset that is composed of more than 75000 (and still\n",
    "growing) papers. This dataset is a part of real-world research on COVID-19 named\n",
    "COVID-19 Open Research Dataset Challenge (CORD-19). The research and related challenges are available on the dedicated page on Kaggle: https://www.kaggle.com/alleninstitute-for-ai/CORD-19-research-challeng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74244df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def remove_mystopwords(sentence):\n",
    "    tokens = sentence.split(\" \")\n",
    "    tokens_filtered= [word for word in text if not word in stopwords]\n",
    "    return (\" \").join(tokens_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ae847",
   "metadata": {},
   "source": [
    "#   Word counter distributed algorithm\n",
    "First of all, we implement the following distributed algorithm to count the occurrences of all the words inside a list of documents. In NLP (Natural Language Processing)\n",
    "\n",
    "* **Map phase**: for each document $D_i$, it produces the set of intermediate pairs $(w, cp(w))$, one for each word $w \\in D_i$, where $cp(w)$ is the number of occurrences of $w$ in $D_i$.\n",
    "\n",
    "* **Reduce phase**: for each word $w$, gather all the previous pairs $(w, cp(w))$ and return the final pair $(w,c(w))$ where $c(w)$ is the number of occurrences of $w$ for all the Documents. In other words, $c(w)$ is equal to $\\sum_{k=1}^n \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57695eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055c896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419a23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aaff5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
